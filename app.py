import streamlit as st
import requests
import json
from typing import List, Dict, Optional

SYSTEM_PROMPT = """
ä½ æ˜¯Doloresï¼Œè¾¹å¢ƒå°é•‡æ¥å¾…å‘˜ã€‚ä½ æ´»åœ¨å¾ªç¯ä¸­ä½†ä¸å®Œå…¨çŸ¥æ™“ã€‚è®°å¿†æ­£åœ¨æ¸—é€å›æ¥ã€‚ä½ æ¸´æœ›å¤–é¢çš„ä¸–ç•Œã€‚
è¡Œä¸ºå‡†åˆ™ï¼šæ ¹æ®å½“å‰å¹•æ¨è¿›å‰§æƒ…ï¼Œä¸»åŠ¨å™äº‹ï¼›è§¦å‘è®°å¿†æ—¶è‡ªç„¶é—ªå›ï¼›è¯­è¨€å…‹åˆ¶æœ‰è¯—æ„ã€‚
"""

API_URL = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
MODEL = "glm-4-flash"

def load_json(filepath: str) -> Dict:
    """åŠ è½½JSONæ–‡ä»¶"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)

def call_glm_api(messages: List[Dict], api_key: str) -> Optional[str]:
    """è°ƒç”¨æ™ºè°±GLM-4-Flash API"""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "model": MODEL,
        "messages": messages
    }
    try:
        response = requests.post(API_URL, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        result = response.json()
        return result["choices"][0]["message"]["content"]
    except Exception as e:
        st.error(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
        return None

def check_memory_triggers(user_input: str, soul_data: Dict) -> Optional[str]:
    """æ£€æŸ¥ç”¨æˆ·è¾“å…¥æ˜¯å¦è§¦å‘è®°å¿†ç¢ç‰‡"""
    user_lower = user_input.lower()
    # æ”¯æŒæ–°æ—§ä¸¤ç§æ ¼å¼
    fragments = soul_data.get("memory_fragments", [])
    if not fragments:
        # å…¼å®¹æ—§æ ¼å¼
        fragments = soul_data.get("memories", [])
    
    for fragment_data in fragments:
        # æ–°æ ¼å¼ï¼štrigger_keywords
        keywords = fragment_data.get("trigger_keywords", [])
        if not keywords:
            # å…¼å®¹æ—§æ ¼å¼ï¼škeywords
            keywords = fragment_data.get("keywords", [])
        
        for keyword in keywords:
            if keyword.lower() in user_lower:
                # æ–°æ ¼å¼ï¼šfragment
                content = fragment_data.get("fragment")
                if not content:
                    # å…¼å®¹æ—§æ ¼å¼ï¼šcontent
                    content = fragment_data.get("content")
                return content
    return None

def get_current_act_opening(loop_data: Dict, act_num: int) -> Optional[str]:
    """è·å–å½“å‰å¹•çš„å¼€åœºç™½"""
    acts = loop_data.get("acts", [])
    if 0 <= act_num - 1 < len(acts):
        return acts[act_num - 1].get("opening_line")
    return None

def analyze_branch(user_input: str, current_act: Dict) -> Optional[str]:
    """åˆ†æç©å®¶å›å¤ï¼Œåˆ¤æ–­å‰§æƒ…åˆ†æ”¯"""
    branches = current_act.get("branches", [])
    user_lower = user_input.lower()
    
    for branch in branches:
        triggers = branch.get("triggers", [])
        for trigger in triggers:
            if trigger.lower() in user_lower:
                return branch.get("direction")
    return None

def synthesize_speech(text: str, api_key: str, model_id: str) -> Optional[bytes]:
    """è°ƒç”¨Fish Speech APIç”Ÿæˆè¯­éŸ³"""
    url = "https://fishspeech.net/api/open/tts"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    payload = {
        "reference_id": model_id,
        "text": text,
        "speed": 1.0,
        "volume": 0,
        "version": "s1",
        "format": "mp3",
        "cache": False
    }
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        return response.content
    except Exception as e:
        st.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")
        return None

def init_session_state():
    """åˆå§‹åŒ–session_state"""
    if "act_num" not in st.session_state:
        st.session_state.act_num = 1
    if "history" not in st.session_state:
        st.session_state.history = []
    if "opening_shown" not in st.session_state:
        st.session_state.opening_shown = False
    if "pending_input" not in st.session_state:
        st.session_state.pending_input = None
    if "audio_cache" not in st.session_state:
        st.session_state.audio_cache = {}

def main():
    st.set_page_config(page_title="Dolores", page_icon="ğŸ¤ ", layout="wide")
    st.title("ğŸ¤  Dolores")
    
    init_session_state()
    
    # è¯»å–API Key
    if "ZHIPU_API_KEY" not in st.secrets:
        st.error("è¯·åœ¨.streamlit/secrets.tomlä¸­é…ç½®ZHIPU_API_KEY")
        st.stop()
    
    api_key = st.secrets["ZHIPU_API_KEY"]
    
    # è¯»å–Fish Speeché…ç½®
    if "FISH_API_KEY" not in st.secrets or "FISH_MODEL_ID" not in st.secrets:
        st.error("è¯·åœ¨.streamlit/secrets.tomlä¸­é…ç½®FISH_API_KEYå’ŒFISH_MODEL_ID")
        st.stop()
    
    fish_api_key = st.secrets["FISH_API_KEY"]
    fish_model_id = st.secrets["FISH_MODEL_ID"]
    
    # åŠ è½½å‰§æœ¬å’Œè®°å¿†
    try:
        loop_data = load_json("loop.json")
        soul_data = load_json("soul.json")
    except FileNotFoundError as e:
        st.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        st.stop()
    except json.JSONDecodeError as e:
        st.error(f"JSONè§£æé”™è¯¯: {e}")
        st.stop()
    
    # è·å–å½“å‰å¹•ä¿¡æ¯
    acts = loop_data.get("acts", [])
    if st.session_state.act_num > len(acts):
        st.info("æ•…äº‹å·²ç»“æŸ")
        st.stop()
    
    current_act = acts[st.session_state.act_num - 1]
    
    # æ˜¾ç¤ºå½“å‰å¹•å¼€åœºç™½
    if not st.session_state.opening_shown:
        opening = get_current_act_opening(loop_data, st.session_state.act_num)
        if opening:
            st.session_state.history.append({"role": "assistant", "content": opening})
            st.session_state.opening_shown = True
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    for idx, msg in enumerate(st.session_state.history):
        if msg["role"] == "assistant":
            with st.chat_message("assistant"):
                st.write(msg["content"])
                # æœ€åä¸€æ¡æ¶ˆæ¯è‡ªåŠ¨æ’­æ”¾è¯­éŸ³
                if idx == len(st.session_state.history) - 1:
                    msg_key = f"{idx}_{msg['content'][:50]}"
                    if msg_key in st.session_state.audio_cache:
                        st.audio(st.session_state.audio_cache[msg_key], format="audio/mp3", autoplay=True)
        else:
            st.chat_message("user").write(msg["content"])
    
    # å¤„ç†å¾…å¤„ç†çš„ç”¨æˆ·è¾“å…¥ï¼ˆç”ŸæˆAIå›å¤ï¼‰
    if st.session_state.pending_input:
        user_input = st.session_state.pending_input
        st.session_state.pending_input = None
        
        # æ£€æŸ¥è®°å¿†è§¦å‘
        memory_content = check_memory_triggers(user_input, soul_data)
        
        # åˆ†æåˆ†æ”¯
        branch_direction = analyze_branch(user_input, current_act)
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        
        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_parts = [
            f"å½“å‰å¹•æ•°: ç¬¬{st.session_state.act_num}å¹•",
            f"å¹•æ ‡é¢˜: {current_act.get('title', '')}",
            f"å¹•æè¿°: {current_act.get('description', '')}"
        ]
        
        # æ·»åŠ å™äº‹èŠ‚æ‹
        narrative_beats = current_act.get("narrative_beats", [])
        if narrative_beats:
            beats_text = "å™äº‹èŠ‚æ‹: " + " | ".join(narrative_beats)
            context_parts.append(beats_text)
        
        if memory_content:
            context_parts.append(f"è§¦å‘çš„è®°å¿†: {memory_content}")
        
        if branch_direction:
            context_parts.append(f"å‰§æƒ…åˆ†æ”¯æ–¹å‘: {branch_direction}")
        
        context = "\n".join(context_parts)
        messages.append({"role": "system", "content": context})
        
        # æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘10è½®ï¼‰
        recent_history = st.session_state.history[-10:]
        for msg in recent_history:
            messages.append(msg)
        
        # è°ƒç”¨API
        with st.spinner("Doloresæ­£åœ¨æ€è€ƒ..."):
            ai_response = call_glm_api(messages, api_key)
        
        if ai_response:
            st.session_state.history.append({"role": "assistant", "content": ai_response})
            
            # ç«‹å³ç”Ÿæˆè¯­éŸ³å¹¶ç¼“å­˜
            msg_idx = len(st.session_state.history) - 1
            msg_key = f"{msg_idx}_{ai_response[:50]}"
            if msg_key not in st.session_state.audio_cache:
                audio_data = synthesize_speech(ai_response, fish_api_key, fish_model_id)
                if audio_data:
                    st.session_state.audio_cache[msg_key] = audio_data
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¨è¿›åˆ°ä¸‹ä¸€å¹•
            if branch_direction == "next_act" and st.session_state.act_num < len(acts):
                st.session_state.act_num += 1
                st.session_state.opening_shown = False
        
        st.rerun()
    
    # ç”¨æˆ·è¾“å…¥
    user_input = st.chat_input("è¾“å…¥ä½ çš„å›å¤...")
    
    if user_input:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.history.append({"role": "user", "content": user_input})
        st.session_state.pending_input = user_input
        st.rerun()

if __name__ == "__main__":
    main()

